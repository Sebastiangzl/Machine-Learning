{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><center>TRABAJO FINAL</center></h1>\n",
        "\n",
        "<hr>\n",
        "<center>\n",
        "\n",
        "<h3>Laura Tatiana Cobos Valbuena - 20201135036<br>\n",
        "Joan Sebastián García Zapata - 20201135087</h3>\n",
        "\n",
        "<center>Electiva - Machine Learning\n",
        "<hr>\n",
        "\n",
        "1. Limpieza de datos.\n",
        "2. Analisis descriptivo. (Histogramas, gráficos)\n",
        "3. Técnicas de Ml.\n",
        " - Regresión logística\n",
        " - Decision tree\n",
        " - Random forest\n",
        " - SVM\n",
        " - ... SGD, boosting, gradient boost ...)\n",
        "4. Mejorar técnicas con Cross-Validation."
      ],
      "metadata": {
        "id": "dhVoMK3JrOEB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LI0lTRypuoP"
      },
      "outputs": [],
      "source": [
        "# Carga de librerías y lectura del archivo que contiene los datos\n",
        "\n",
        "import numpy as np # Cálculo numérico y el análisis de datos\n",
        "import pandas as pd # Manejo y análisis de estructuras de datos\n",
        "import sklearn as sk # Útil para Machine Learning, proporciona algoritmos de aprendizaje supervisados y no supervisados.\n",
        "import seaborn as sns # Proporciona una interfaz de alto nivel para crear gráficos estadísticos\n",
        "import matplotlib.pyplot as plt # Realizar gráficos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<blockquote> Cada candidato se describe mediante 7 variables continuas y de dos variables de clase:<br>\n",
        "\n",
        "   - **objid**. Tipo numérico. <br>\n",
        "   - **ra**. Tipo numérico. <br> \n",
        "   - **dec**. Tipo numérico. <br>\n",
        "   - **u**. Tipo categórico. <br>\n",
        "   - **g**. Tipo categórico. <br>\n",
        "   - **r**. Tipo numérico. <br>\n",
        "   - **i**. Tipo numérico. <br>\n",
        "   - **z**: Tipo numérico <br>\n",
        "   - **run**: Tipo numérico. <br>\n",
        "   - **rerun**: Tipo numérico. <br>\n",
        "   - **camcol**: Tipo numérico. <br>\n",
        "   - **field**: Tipo numérico. <br>\n",
        "   - **specobjid**:Tipo numérico. <br>\n",
        "   - **class**: Clase. Tipo categórico. <br>\n",
        "   - **redshift**: Tipo numérico. <br>\n",
        "   - **plate**: Tipo numérico. <br>\n",
        "   - **mjd**: Tipo numérico. <br>\n",
        "   - **fiberid**: Tipo numérico. <br>\n",
        "</blockquote>\n",
        "\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t"
      ],
      "metadata": {
        "id": "gRxtNjz5eM8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Visualización de la base de datos</h1>"
      ],
      "metadata": {
        "id": "arFhci1kfB8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sep como tabulador y decimal para representar \",\" como decimal.\n",
        "df_ht=pd.read_csv(\"https://raw.githubusercontent.com/LauraCocos/ElectivaML/main/DatosAstrofisicos.csv\") \n",
        "df_ht"
      ],
      "metadata": {
        "id": "U7TJaBUCp4EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Tamaño del data_set</h1>"
      ],
      "metadata": {
        "id": "uHgKlvm8ex7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Para mostrar el tamaño de la base de datos\n",
        "df_ht.shape"
      ],
      "metadata": {
        "id": "FwkO6pHmr_rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Información general de la base de datos</h1>"
      ],
      "metadata": {
        "id": "kHhJOuFwfImG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos el método info() para obtener información de las columnas del dataset.\n",
        "df_ht.info()"
      ],
      "metadata": {
        "id": "nLbsewVbuFLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Verificación de los valores nulos</h1>"
      ],
      "metadata": {
        "id": "bSwW65YGfN6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificamos el total de valores nulos en cada columna. \n",
        "df_ht.isna().sum()"
      ],
      "metadata": {
        "id": "OHLyauWbvU4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Identificación de outliers</h1>"
      ],
      "metadata": {
        "id": "aQGsCicTfSi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EKIP = [df_ht[\"u\"], df_ht[\"g\"], df_ht[\"r\"],df_ht[\"i\"], df_ht[\"z\"]]\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.boxplot(EKIP)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sLuaML2Wv1Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EKIP2 = [df_ht[\"run\"], df_ht[\"rerun\"], df_ht[\"field\"],df_ht[\"fiberid\"], df_ht[\"camcol\"], df_ht[\"dec\"], df_ht[\"ra\"], df_ht[\"camcol\"]] \t\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.boxplot(EKIP2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sba07PI_xs9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EKIP3 = [df_ht[\"objid\"], df_ht[\"specobjid\"]] \t\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.boxplot(EKIP3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xWZ6nwoczBVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ht[\"plate\"]\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.boxplot(df_ht[\"plate\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JeX7B_Z70Ra4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ht[\"redshift\"]\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.boxplot(df_ht[\"redshift\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EvBq53dE4Co7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Optimización de los outliers</h1>"
      ],
      "metadata": {
        "id": "rK4FKpMhfXTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------------- #\n",
        "\n",
        "# Usamos el método quantile() para obtener los cuartiles 1 (25%) y 3 (75%)\n",
        "pl_q1 = df_ht['plate'].quantile(0.25)\n",
        "pl_q3 = df_ht['plate'].quantile(0.75)\n",
        "\n",
        "# Calculamos el rango intercuartil\n",
        "pl_iqr = pl_q3 - pl_q1\n",
        "\n",
        "# Calculamos el valor de los bigotes inferior y superior\n",
        "pl_lw = pl_q1 - (1.5 * pl_iqr)\n",
        "pl_uw = pl_q3 + (1.5 * pl_iqr)\n",
        "\n",
        "# Verificamos los resultados\n",
        "print('----------- Resultados columna plate -----------')\n",
        "print('Primer cuartil: ', pl_q1)\n",
        "print('Tercer cuartil: ', pl_q3)\n",
        "print('Rango intercuartil: ', pl_iqr)\n",
        "print('Bigote inferior: ', pl_lw)\n",
        "print('Bigote superior: ', pl_uw, '\\n')\n",
        "\n",
        "# --------------------------------------------------------------------------------- #\n",
        "\n",
        "red_q1 = df_ht['redshift'].quantile(0.25)\n",
        "red_q3 = df_ht['redshift'].quantile(0.75)\n",
        "\n",
        "red_iqr = red_q3 - red_q1\n",
        "\n",
        "red_lw = red_q1 - (1.5 * red_iqr)\n",
        "red_uw = red_q3 + (1.5 * red_iqr)\n",
        "\n",
        "print('----------- Resultados columna redshift -----------')\n",
        "print('Primer cuartil: ', red_q1)\n",
        "print('Tercer cuartil: ', red_q3)\n",
        "print('Rango intercuartil: ', red_iqr)\n",
        "print('Bigote inferior: ', red_lw)\n",
        "print('Bigote superior: ', red_uw, '\\n')\n",
        "\n",
        "# --------------------------------------------------------------------------------- #\n",
        "\n",
        "spe_q1 = df_ht['specobjid'].quantile(0.25)\n",
        "spe_q3 = df_ht['specobjid'].quantile(0.75)\n",
        "\n",
        "spe_iqr = spe_q3 - spe_q1\n",
        "\n",
        "spe_lw = spe_q1 - (1.5 * spe_iqr)\n",
        "spe_uw = spe_q3 + (1.5 * spe_iqr)\n",
        "\n",
        "print('----------- Resultados columna specobjid -----------')\n",
        "print('Primer cuartil: ', spe_q1)\n",
        "print('Tercer cuartil: ', spe_q3)\n",
        "print('Rango intercuartil: ', spe_iqr)\n",
        "print('Bigote inferior: ', spe_lw)\n",
        "print('Bigote superior: ', spe_uw)\n",
        "\n",
        "# --------------------------------------------------------------------------------- #"
      ],
      "metadata": {
        "id": "eyT5-Q726RLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Reemplazo de los outliers por la mediana</h1>"
      ],
      "metadata": {
        "id": "nfCcoZVOfdHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Armamos una condición lógica y la guardamos en una variable.\n",
        "pl_outliers = (df_ht['plate'] < pl_lw) | (df_ht['plate'] > pl_uw)\n",
        "red_outliers = (df_ht['redshift'] < red_lw) | (df_ht['redshift'] > red_uw)\n",
        "spe_outliers = (df_ht['specobjid'] < spe_lw) | (df_ht['specobjid'] > spe_uw)\n",
        "\n",
        "# Usamos el atributo loc para acceder a todos los registros que cumplan la condición especificada y reemplazamos todos los \n",
        "# valores de dichos registros para la columna elegida con el valor nulo.\n",
        "df_ht.loc[pl_outliers, 'plate'] = np.nan\n",
        "df_ht.loc[red_outliers, 'redshift'] = np.nan\n",
        "df_ht.loc[spe_outliers, 'specobjid'] = np.nan\n",
        "\n",
        "# Volvemos a usar los métodos isna() y sum() para verificar los valores nulos de cada columna.\n",
        "df_ht.isna().sum()"
      ],
      "metadata": {
        "id": "-0AMFtGZ6hmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos la columna, la guardamos en una variable y con el método dropna() quitamos los valores nulos\n",
        "# para que al dibujar la gráfica de histograma no nos dé ningún problema.\n",
        "plate = df_ht['plate']\n",
        "redshift = df_ht['redshift']\n",
        "specobjid = df_ht['specobjid']\n",
        "\n",
        "# Usamos la gráfica de histograma para ver la distribución de los datos.\n",
        "\n",
        "plt.figure(figsize=(4, 3))\n",
        "plt.hist(plate)\n",
        "plt.title(\"Distribución de la columna plate\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dGRi1m656_9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4, 3))\n",
        "plt.hist(redshift)\n",
        "plt.title(\"Distribución de la columna redshift\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nhc2ZTYOZg2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4, 3))\n",
        "plt.hist(specobjid)\n",
        "plt.title(\"Distribución de la columna specobjid\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iv6x89suZpft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este histograma nos muestra una forma de campana desviada hacia la izquierda, por lo que la mejor estrategia de imputación para esta columna es reemplazar los valores nulos por la mediana."
      ],
      "metadata": {
        "id": "jrVQEPc8_x2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos el método median() para obtener el valor de la mediana y lo guardamos en una variable.\n",
        "pl_median = plate.median()\n",
        "red_median = redshift.median()\n",
        "spe_median = specobjid.median()\n",
        "\n",
        "# Con el método fillna() reemplazamos los valores nulos de una columna por un nuevo valor.\n",
        "df_ht.fillna(value={'plate': pl_median}, inplace=True)\n",
        "df_ht.fillna(value={'redshift': red_median}, inplace=True)\n",
        "df_ht.fillna(value={'specobjid': spe_median}, inplace=True)\n",
        "\n",
        "# Verificamos nuevamente el número de nulos.\n",
        "df_ht.isnull().sum()"
      ],
      "metadata": {
        "id": "liHFCH4t_99o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Balanceo de datos</h1>"
      ],
      "metadata": {
        "id": "UTJXJs9FflEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se hace balanceo de clases eliminando ejemplos de la clase mayoritaria\n",
        "g = df_ht.groupby('class')\n",
        "dataBal = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True)))\n",
        "dataBal"
      ],
      "metadata": {
        "id": "BRmVwcsXdz7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se verifica que haya quedado el mismo número de registros por cada clase\n",
        "print(dataBal['class'].value_counts())"
      ],
      "metadata": {
        "id": "LfWWimKcd66s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>División de la base de datos (Balanceada)</h1>"
      ],
      "metadata": {
        "id": "s1YM8O1pfphA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir el conjunto de datos en conjuntos de train y test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataBal.drop('class', axis=1), dataBal[\"class\"], test_size=0.20)\n",
        "print (X_train.shape, y_train.shape)\n",
        "print (X_test.shape, y_test.shape)\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "dataBal = shuffle(dataBal)"
      ],
      "metadata": {
        "id": "rVcUl3oMdBjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Entrenamiento por regresión logística</h1>"
      ],
      "metadata": {
        "id": "1jkmm5YDfvY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo de clasificación por regresión logística\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Escalar las características\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(X_train)\n",
        "\n",
        "# Crear y ajustar el modelo con los datos escalados\n",
        "logisticRegr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "logisticRegr.fit(scaled_features, y_train)"
      ],
      "metadata": {
        "id": "PoZcHZZjezmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Para graficar la matriz de confusión\n",
        "predictions = logisticRegr.predict(X_test)\n",
        "matriz1 = confusion_matrix(y_test,predictions)\n",
        "\n",
        "plot_confusion_matrix(conf_mat=matriz1, figsize=(4,4), show_normed=False)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "GjoFk0tlkxpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Entrenamiento por árbol de decisión</h1>"
      ],
      "metadata": {
        "id": "1rJQRup7fz5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "X = dataBal.iloc[:,0:17] #Variables predictores\n",
        "Y = dataBal.iloc[:,17] #Variables a predecir\n",
        "\n",
        "#Llamamos el modelo de construcción del árbol\n",
        "arbol = DecisionTreeClassifier() # Max_depth= nos permite regular el tamaño del arbol\n",
        "\n",
        "#Consutrucción del árbol de desiciones\n",
        "arbolh = arbol.fit(X_train, y_train)\n",
        "arbol_fig = plt.figure(figsize=(15,15))\n",
        "tree.plot_tree(arbolh, feature_names=list(X.columns.values), class_names=np.array(sorted(Y.unique())).astype('str').tolist(), filled=True, rounded=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "burag7tRi49k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicación del modelo construido a los datos de test (Se preciden los datos)\n",
        "predictions2 = arbol.predict(X_test)\n",
        "print(predictions2)\n",
        "print(list(y_test)) #El y_test trae los datos de la parte del 80% del data"
      ],
      "metadata": {
        "id": "NGBejnhung5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Entrenamiento por bosque aleatorio (No se grafica debido a que toca graficar los árboles uno por uno)</h1>"
      ],
      "metadata": {
        "id": "dVoDQbyIf_KF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librería RandomForestClassifier en la función sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# =(Número de árboles, semilla para aleatoriedad, mínima cantidad de muestras en una división)\n",
        "bosque = RandomForestClassifier(n_estimators=1000, random_state=1000, min_samples_leaf = 1)\n",
        "\n",
        "#Realizamos el entrenamiento\n",
        "bosque.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Z08qvDy1oXR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicación del modelo construido a los datos de test (Se preciden los datos)\n",
        "predictions3 = bosque.predict(X_test)\n",
        "print(predictions3)\n",
        "print(list(y_test)) #El y_test trae los datos de la parte del 80% del data"
      ],
      "metadata": {
        "id": "8ZuNm-FqnZk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Modelo SMV con kernel lineal<h1>"
      ],
      "metadata": {
        "id": "Toqyc9YNoOch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import svm model\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clfD = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clfD.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "yD_pred = clfD.predict(X_test)"
      ],
      "metadata": {
        "id": "7eC9FdXHodwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicación del modelo construido a los datos de test (Se preciden los datos)\n",
        "predictions5 = clfD.predict(X_test)\n",
        "print(predictions5)\n",
        "print(list(y_test)) #El y_test trae los datos de la parte del 80% del data"
      ],
      "metadata": {
        "id": "rbt4dL_PoixG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Modelo SMV con kernel rbf<h1>"
      ],
      "metadata": {
        "id": "1KJo0LK3opsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a svm Classifier\n",
        "clf12 = svm.SVC(kernel='rbf') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf12.fit(X12_train, y12_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred3 = clf12.predict(X12_test)"
      ],
      "metadata": {
        "id": "heAj6XxjoxtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicación del modelo construido a los datos de test (Se preciden los datos)\n",
        "predictions6 = clf12.predict(X_test)\n",
        "print(predictions6)\n",
        "print(list(y_test)) #El y_test trae los datos de la parte del 80% del data"
      ],
      "metadata": {
        "id": "_WJu3MsmozeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Modelo de SGDClassifier</h1>"
      ],
      "metadata": {
        "id": "E73NkCTZgIqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# ajusta el modelo\n",
        "clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=5000, fit_intercept=True)\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "H5zrgGEbsGoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Para convertir los tipos de object a int64 o float (Es este caso binario)\n",
        "\n",
        "labelencoder= LabelEncoder() \n",
        "dataBal['class'] = labelencoder.fit_transform(dataBal['class'])\n",
        "\n",
        "# Obtener los predictores y la variable objetivo\n",
        "predictors = dataBal[['ra', 'dec', 'redshift']]  # Selecciona los predictores que deseas utilizar\n",
        "target = dataBal['class']  # Variable objetivo 'class' con las etiquetas 'STAR', 'GALAXY' y 'QSO'\n",
        "\n",
        "# Ajustar el modelo de clasificación con SGD\n",
        "sgd = SGDClassifier(random_state=42)\n",
        "sgd.fit(predictors, target)\n",
        "\n",
        "# Crear una malla de puntos en el espacio de características\n",
        "ra_range = np.linspace(predictors['ra'].min(), predictors['ra'].max(), 10)\n",
        "dec_range = np.linspace(predictors['dec'].min(), predictors['dec'].max(), 10)\n",
        "redshift_range = np.linspace(predictors['redshift'].min(), predictors['redshift'].max(), 10)\n",
        "ra_mesh, dec_mesh, redshift_mesh = np.meshgrid(ra_range, dec_range, redshift_range)\n",
        "\n",
        "# Predecir las etiquetas para la malla de puntos\n",
        "predicted_labels = sgd.predict(np.c_[ra_mesh.ravel(), dec_mesh.ravel(), redshift_mesh.ravel()])\n",
        "predicted_labels = predicted_labels.reshape(ra_mesh.shape)\n",
        "\n",
        "# Graficar los datos en 3D\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(predictors['ra'], predictors['dec'], predictors['redshift'], c=target, cmap='coolwarm')\n",
        "\n",
        "# Graficar la superficie de decisión\n",
        "ax.scatter(ra_mesh[predicted_labels=='STAR'], dec_mesh[predicted_labels=='STAR'], redshift_mesh[predicted_labels=='STAR'], c='darkred', marker='o', label='STAR')\n",
        "ax.scatter(ra_mesh[predicted_labels=='GALAXY'], dec_mesh[predicted_labels=='GALAXY'], redshift_mesh[predicted_labels=='GALAXY'], c='lightgray', marker='o', label='GALAXY')\n",
        "ax.scatter(ra_mesh[predicted_labels=='QSO'], dec_mesh[predicted_labels=='QSO'], redshift_mesh[predicted_labels=='QSO'], c='b', marker='o', label='QSO')\n",
        "\n",
        "# Configurar etiquetas y título\n",
        "ax.set_xlabel('ra')\n",
        "ax.set_ylabel('dec')\n",
        "ax.set_zlabel('redshift')\n",
        "ax.legend()\n",
        "plt.title('Modelo de clasificación SGD')\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xocw_B0-KBGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicación del modelo construido a los datos de test (Se preciden los datos)\n",
        "predictions4 = clf.predict(X_test)\n",
        "print(predictions4)\n",
        "print(list(y_test)) #El y_test trae los datos de la parte del 80% del data"
      ],
      "metadata": {
        "id": "kGOLY9-bnuFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Modelos Gradient Boosting Trees</h1>"
      ],
      "metadata": {
        "id": "w8980KOFs1jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación del modelo\n",
        "# ==============================================================================\n",
        "mgbt = GradientBoostingRegressor(\n",
        "            n_estimators = 10,\n",
        "            loss         = 'ls',\n",
        "            max_features = 'auto',\n",
        "            random_state = 123\n",
        "         )\n",
        "# Entrenamiento del modelo\n",
        "# ==============================================================================\n",
        "mgbt.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ypXqVnnLtRAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicciones = modelo.predict(X = X_test)\n",
        "\n",
        "rmse = mean_squared_error(\n",
        "        y_true  = y_test,\n",
        "        y_pred  = predicciones,\n",
        "        squared = False\n",
        "       )\n",
        "print(\"El error (rmse) de test es: {rmse}\")"
      ],
      "metadata": {
        "id": "nECqt3P7tsH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Técnicas con cross-Validation</h1>"
      ],
      "metadata": {
        "id": "02LB7MA_pkTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "modelo1=LogisticRegression()\n",
        "modelo2=DecisionTreeClassifier()\n",
        "modelo3=RandomForestClassifier()\n",
        "modelo4=svm.SVC(kernel='linear')\n",
        "modelo5=svm.SVC(kernel='rbf')\n",
        "modelo6=SGDClassifier()\n",
        "\n",
        "predicciones_val1=modelo1.predict(X_test)\n",
        "predicciones_val2=modelo2.predict(X_test)\n",
        "predicciones_val3=modelo3.predict(X_test)\n",
        "predicciones_val4=modelo4.predict(X_test)\n",
        "predicciones_val5=modelo5.predict(X_test)\n",
        "predicciones_val6=modelo6.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, predicciones_val1))\n",
        "print(classification_report(y_test, predicciones_val2))\n",
        "print(classification_report(y_test, predicciones_val3))\n",
        "print(classification_report(y_test, predicciones_val4))\n",
        "print(classification_report(y_test, predicciones_val5))\n",
        "print(classification_report(y_test, predicciones_val6))"
      ],
      "metadata": {
        "id": "AZjfSDKLqKW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "divisiones=KFold(n_splits=5)\n",
        "\n",
        "metricas1=cross_val_score(modelo1,X,y, cv= divisiones)\n",
        "metricas2=cross_val_score(modelo2,X,y, cv= divisiones)\n",
        "metricas3=cross_val_score(modelo3,X,y, cv= divisiones)\n",
        "metricas4=cross_val_score(modelo4,X,y, cv= divisiones)\n",
        "metricas5=cross_val_score(modelo5,X,y, cv= divisiones)\n",
        "metricas6=cross_val_score(modelo6,X,y, cv= divisiones)\n",
        "\n",
        "\n",
        "print(\"---------- Modelo cross validation con regresión logística ----------\")\n",
        "print(\"Cross Validation Scores: \", metricas1)\n",
        "print(\"Average CV Score: \", metricas1.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(metricas1))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"---------- Modelo cross validation con árbol de decisión ----------\")\n",
        "print(\"Cross Validation Scores: \", metricas2)\n",
        "print(\"Average CV Score: \", metricas2.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(metricas2))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"---------- Modelo cross validation con bosque aleatorio ----------\")\n",
        "print(\"Cross Validation Scores: \", metricas3)\n",
        "print(\"Average CV Score: \", metricas3.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(metricas3))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"---------- Modelo cross validation con smv kernel lineal ----------\")\n",
        "print(\"Cross Validation Scores: \", metricas4)\n",
        "print(\"Average CV Score: \", metricas4.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(metricas4))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"---------- Modelo cross validation con smv kernel rbf ----------\")\n",
        "print(\"Cross Validation Scores: \", metricas5)\n",
        "print(\"Average CV Score: \", metricas5.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(metricas5))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"---------- Modelo cross validation con clasificador SGD ----------\")\n",
        "print(\"Cross Validation Scores: \", metricas6)\n",
        "print(\"Average CV Score: \", metricas6.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(metricas6))"
      ],
      "metadata": {
        "id": "VF1H4bH5qY68"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}